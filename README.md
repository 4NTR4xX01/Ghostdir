# ğŸ•µï¸â€â™‚ï¸ GHOSTDIR -  Enumerador Pasivo de Directorios y Subdominios

![banner](images/banner.png)

Este script realiza **enumeraciÃ³n pasiva** de URLs, subdominios y directorios a partir de mÃºltiples fuentes pÃºblicas como Wayback Machine, Common Crawl, y crt.sh, sin enviar trÃ¡fico al objetivo.

âš¡ **Todo el proceso es 100% pasivo y seguro.**

---

## ğŸ“¦ Requisitos

Antes de ejecutar el script, asegÃºrate de tener instaladas las siguientes herramientas:

| Herramienta | InstalaciÃ³n | DescripciÃ³n |
|:--|:--|:--|
| `waybackurls` | `go install github.com/tomnomnom/waybackurls@latest` | Recupera URLs archivadas. |
| `gau` | `go install github.com/lc/gau/v2/cmd/gau@latest` | Recolecta URLs desde servicios como Wayback, Common Crawl, etc. |
| `amass` | `sudo apt install amass` **o** `go install github.com/owasp-amass/amass/v3/...@master` | Recolector de subdominios. |
| `jq` | `sudo apt install jq` | Procesador de JSON para bash. |
| `curl` | `sudo apt install curl` | Para realizar consultas HTTP. |
| `sed`, `awk`, `grep`, `sort`, `timeout`, `mkdir` | Generalmente ya vienen preinstaladas en Linux/macOS. |

**Importante:**  
Instala [Go](https://golang.org/dl/) si no tienes `go install` disponible (`sudo apt install golang` en Debian/Ubuntu).

---

## ğŸ›  InstalaciÃ³n rÃ¡pida

```bash
# Instalar dependencias principales (Debian/Ubuntu)
sudo apt update
sudo apt install curl jq amass sed grep awk coreutils timeout

# Instalar herramientas Go
go install github.com/tomnomnom/waybackurls@latest
go install github.com/lc/gau/v2/cmd/gau@latest
```

**DespuÃ©s de instalar**, asegÃºrate de que `$GOPATH/bin` estÃ© en tu `$PATH`, por ejemplo:

```bash
export PATH=$PATH:$(go env GOPATH)/bin
```

---

## ğŸš€ Uso

```bash
git clone https://github.com/4NTR4xX01/Ghostdir.git
cd Ghostdir
chmod +x Ghostdir.sh
./Ghostdir.sh ejemplo.com
```

**ParÃ¡metro obligatorio:**  
- `ejemplo.com` â†’ El dominio objetivo (sin `https://`, solo el nombre).

---

## ğŸ“‚ Â¿QuÃ© genera el script?

Se crea una carpeta `enumeracion_<dominio>` con estos archivos:

- `wayback.txt` â†’ URLs desde Wayback Machine.
- `gau.txt` â†’ URLs desde mÃºltiples fuentes.
- `commoncrawl.txt` â†’ URLs desde Common Crawl.
- `crtsh_subdomains.txt` â†’ Subdominios de crt.sh.
- `amass_subdomains.txt` â†’ Subdominios desde Amass (modo pasivo).
- `directorios_finales.txt` â†’ Directorios Ãºnicos extraÃ­dos de las URLs.
- `archivos_sensibles.txt` â†’ Posibles archivos sensibles (`.zip`, `.sql`, `.env`, etc.).
- `directorio_wordlist.txt` â†’ Wordlist para fuzzing de directorios.
- `directorios.csv` â†’ Listado en formato CSV.
- `directorios.html` â†’ Archivo HTML navegable con enlaces.

---

## ğŸ§  Â¿QuÃ© hace exactamente el script?

1. Recopila URLs histÃ³ricas de varias fuentes pÃºblicas.
2. Extrae los **directorios** Ãºnicos.
3. Detecta rutas que parecen apuntar a **archivos sensibles**.
4. Crea exportaciones en **CSV** y **HTML**.
5. Genera una **wordlist** para posibles fuzzings.

âœ… **Todo sin enviar ni un solo paquete al dominio objetivo.**

---

## âš¡ Ejemplo de ejecuciÃ³n

```bash
./Ghostdir.sh testphp.vulnweb.com
```

Salida:

![salida](images/salida.png)

---

## ğŸ›¡ï¸ Aviso Legal

Este script estÃ¡ diseÃ±ado **Ãºnicamente para fines educativos y de evaluaciÃ³n Ã©tica**.  
El autor no se hace responsable del mal uso.

**Usa este script Ãºnicamente en dominios que te pertenezcan o tengas permiso de evaluar.**
